{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # dataframes and csv\n",
    "import numpy as np # linear algebra\n",
    "import sklearn as sk # data maniputation\n",
    "import matplotlib.pyplot as plt # data visualization\n",
    "import re # regular expressions for the text\n",
    "import tensorflow as tf # for ML\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tokenizers import SentencePieceBPETokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.pre_tokenizers import PreTokenizer\n",
    "from tokenizers import SentencePieceBPETokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_train = pd.read_csv(\"./archive/train.csv\",header=None, names=['sentiment', 'short_text','text'])\n",
    "reviews_test = pd.read_csv(\"./archive/test.csv\",header=None, names=['sentiment', 'short_text','text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200000\n"
     ]
    }
   ],
   "source": [
    "training_sentences = []\n",
    "training_labels = []\n",
    "\n",
    "testing_sentences = []\n",
    "testing_labels = []\n",
    "\n",
    "# Loop over all training examples and save the sentences and labels\n",
    "for t in reviews_train[\"text\"]:\n",
    "  training_sentences.append(t)\n",
    "\n",
    "for t in reviews_train[\"short_text\"]:\n",
    "  training_sentences.append(t)\n",
    "\n",
    "\n",
    "for s in reviews_train[\"sentiment\"]:\n",
    "  if s == 2: # Redo the labels so the processing is faster \n",
    "    training_labels.append(1)\n",
    "  else:\n",
    "    training_labels.append(0)\n",
    "#do it for the second time so short-text can have sentiments\n",
    "for s in reviews_train[\"sentiment\"]:\n",
    "  if s == 2: \n",
    "    training_labels.append(1)\n",
    "  else:\n",
    "    training_labels.append(0)\n",
    "\n",
    "# Loop over all test examples and save the sentences and labels\n",
    "for t in reviews_test[\"text\"]:\n",
    "  testing_sentences.append(t)\n",
    "\n",
    "for t in reviews_test[\"short_text\"]:\n",
    "  testing_sentences.append(t)\n",
    "\n",
    "\n",
    "for s in reviews_test[\"sentiment\"]:\n",
    "  if s == 2: # Redo the labels so the processing is faster \n",
    "    testing_labels.append(1)\n",
    "  else:\n",
    "    testing_labels.append(0)\n",
    "#do it for the second time so short-text can have sentiments\n",
    "for s in reviews_test[\"sentiment\"]:\n",
    "  if s == 2: \n",
    "    testing_labels.append(1)\n",
    "  else:\n",
    "    testing_labels.append(0)\n",
    "\n",
    "# Convert labels lists to numpy array\n",
    "training_labels_final = np.array(training_labels)\n",
    "testing_labels_final = np.array(testing_labels)\n",
    "\n",
    "\n",
    "print(len(training_labels_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600000\n"
     ]
    }
   ],
   "source": [
    "print(sum(training_labels_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "max_len=0\n",
    "pattern = r'[,\\s!?()._\\-]+'\n",
    "for sentence in training_sentences:\n",
    "    sentence = str(sentence).lower()\n",
    "    sentence = re.split(pattern, sentence) # Split the text based on the pattern\n",
    "    if len(sentence)>max_len:\n",
    "        max_len=len(sentence)\n",
    "    sentence = \" \".join(sentence)\n",
    "    sentences.append(sentence)\n",
    "    \n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"text_2.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for sentence in sentences:\n",
    "        f.write(sentence+\"\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0 ...   51  123   51]\n",
      " [   0    0    0 ...  455 5124  123]\n",
      " [   0    0    0 ...  978  981  123]\n",
      " ...\n",
      " [   0    0    0 ...  663  156 1223]\n",
      " [   0    0    0 ...  163 2313  123]\n",
      " [   0    0    0 ... 1768  158 2220]]\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000\n",
    "trunc_type='pre'\n",
    "oov_tok = \"<OOV>\"\n",
    "\n",
    "BPE_sentence_tokenizer = SentencePieceBPETokenizer()\n",
    "BPE_sentence_tokenizer.train(\"text_2.txt\",vocab_size=vocab_size)\n",
    "\n",
    "encoded_texts = [BPE_sentence_tokenizer.encode(text).ids for text in sentences]\n",
    "# Pad the sequences to a consistent length\n",
    "X = pad_sequences(encoded_texts, maxlen=300, padding='pre')\n",
    "print(X)\n",
    "y = training_labels_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "\n",
    "new_tokenizer = BertTokenizerFast(tokenizer_object=BPE_sentence_tokenizer)\n",
    "BPE_sentence_tokenizer.save('./my_additionally_trained_tokenizer_BPE.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize or load your NLP model\n",
    "model = tf.keras.models.load_model(\"./my_trained_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 5\n",
    "BATCH_SIZE = 128\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.007)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X[:100000], y[:100000], test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(BPE_sentence_tokenizer.get_vocab_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "547/547 [==============================] - 141s 247ms/step - loss: 0.4900 - accuracy: 0.7544 - val_loss: 0.3554 - val_accuracy: 0.8498\n",
      "Epoch 2/5\n",
      "547/547 [==============================] - 178s 325ms/step - loss: 0.3089 - accuracy: 0.8742 - val_loss: 0.3048 - val_accuracy: 0.8750\n",
      "Epoch 3/5\n",
      "547/547 [==============================] - 186s 340ms/step - loss: 0.2508 - accuracy: 0.9017 - val_loss: 0.2982 - val_accuracy: 0.8824\n",
      "Epoch 4/5\n",
      "547/547 [==============================] - 194s 355ms/step - loss: 0.2091 - accuracy: 0.9203 - val_loss: 0.2815 - val_accuracy: 0.8870\n",
      "Epoch 5/5\n",
      "547/547 [==============================] - 186s 341ms/step - loss: 0.1743 - accuracy: 0.9364 - val_loss: 0.2905 - val_accuracy: 0.8818\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1a5c7845390>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,batch_size=BATCH_SIZE, epochs=NUM_EPOCHS, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m model_save_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m./my_additionally_trained_model\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[39m# Save the model\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m model\u001b[39m.\u001b[39msave(model_save_path)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Assuming you have trained your model and stored it in the `model_lstm` variable\n",
    "# Specify the path where you want to save the model\n",
    "model_save_path = './my_additionally_trained_model'\n",
    "\n",
    "# Save the model\n",
    "model.save(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize or load your NLP model\n",
    "model = tf.keras.models.load_model('./my_additionally_trained_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 223ms/step\n",
      "sentence:comedy scene, and not heard right answer0 my answer 1 (Probability: 0.573357343673706\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "sentence:strange but, listenable right answer0 my answer 1 (Probability: 0.6397700309753418\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "sentence:super. right answer1 my answer 0 (Probability: 0.4396395981311798\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "sentence:mac os x server administrator's guide right answer0 my answer 1 (Probability: 0.8991463780403137\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "sentence:huh? the cd's over? best nap i ever took. right answer0 my answer 1 (Probability: 0.9019368290901184\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "sentence:neil armstrong, a good man right answer0 my answer 1 (Probability: 0.9510635733604431\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "sentence:okay at first, but died pretty quickly... right answer0 my answer 1 (Probability: 0.6189634799957275\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "sentence:this is my first pda/organizer right answer1 my answer 0 (Probability: 0.07388534396886826\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "sentence:loquacious and another world right answer0 my answer 1 (Probability: 0.8780534267425537\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "sentence:the nader reader right answer1 my answer 0 (Probability: 0.4865492582321167\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "sentence:if it worked consistently it would be amazing right answer0 my answer 1 (Probability: 0.8369654417037964\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "sentence:derails right answer0 my answer 1 (Probability: 0.8709902763366699\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "sentence:vampires 90210 right answer0 my answer 1 (Probability: 0.5471222996711731\n",
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    }
   ],
   "source": [
    "#THE INPUT SHOULD BE ALWAYS LOWER\n",
    "test = 0\n",
    "for i in range(-1,-50,-1):\n",
    "    input_sentence = testing_sentences[i].lower()\n",
    "    # Preprocess the sentence (lowercase, tokenize, and pad)\n",
    "    input_sequence = BPE_sentence_tokenizer.encode(input_sentence).ids\n",
    "    input_sequence = pad_sequences([input_sequence], maxlen=100, padding='pre')\n",
    "    # Make a prediction\n",
    "    predicted_probability = model.predict(input_sequence)\n",
    "\n",
    "    # Interpret the prediction (assuming binary classification)\n",
    "    if predicted_probability > 0.5:\n",
    "        sentiment = 1\n",
    "        if sentiment==testing_labels[i]:\n",
    "            test=test+1\n",
    "        else:\n",
    "            print(f\"sentence:{input_sentence} right answer{testing_labels[i]} my answer {sentiment} (Probability: {predicted_probability[0][0]}\")\n",
    "    else:\n",
    "        sentiment = 0\n",
    "        if sentiment==testing_labels[i]:\n",
    "            test=test+1\n",
    "        else:\n",
    "            print(f\"sentence:{input_sentence} right answer{testing_labels[i]} my answer {sentiment} (Probability: {predicted_probability[0][0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "print(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
